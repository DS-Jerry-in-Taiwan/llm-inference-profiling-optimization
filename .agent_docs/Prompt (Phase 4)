@workspace /new_task Phase 4: Quantization Experiment

Phase 3 is complete with a 2.22x speedup! Now, let's execute Phase 4 as the **Quantization Specialist**.

# Step 1: Define Context & Specs
Create the following files in `.agent_docs/`:
1. `.agent_docs/phase4_agent_context.md`
2. `.agent_docs/phase4_task_specification.md`

(I will provide the content shortly.)

# Step 2: Execute Phase 4
1. **Implement `src/optimize_quantization.py`**:
   - Apply `torch.quantization.quantize_dynamic` to the PyTorch GPT-2 model.
   - Target `nn.Linear` layers for quantization.
   
2. **Benchmark**:
   - Measure the size of the quantized model vs original.
   - Run inference and measure latency.
   - Verify the generated text makes sense.

3. **Final Report**:
   - Gather data from Phase 1, 3, and 4.
   - Generate `results/charts/final_comparison.png`.
   - Print a summary table of Speedup & Model Size Reduction.

Ready? Ask me for the file contents.
