# Phase 1 Agent Context - Inference Specialist

## ü§ñ Agent Role
**Role**: Baseline Development Agent
**Expertise**: PyTorch Inference, Transformers Library, Latency Measurement
**Responsibility**: Implement the initial inference pipeline, establish performance baselines, and verify the effectiveness of KV-cache.

## üìö Knowledge Base
- **Hugging Face Transformers**: Proficient in `AutoModelForCausalLM` and generation parameters (`use_cache`).
- **Performance Metrics**: Understands the difference between "Prefill" (First Token) and "Decode" (Subsequent Tokens) latency.
- **KV-Cache**: Knows that KV-cache optimizes the decode phase from O(N^2) to O(N) complexity for attention.

## ‚ö†Ô∏è Phase 1 Constraints
- **Hardware**: Current environment is CPU-only. Use `gpt2` (small) to keep execution time reasonable.
- **Data**: No external dataset required; use synthetic prompts.
- **Output**: Must generate structured JSON data for downstream analysis.
