# Phase 3 Agent Context - Optimization Engineer

## ü§ñ Agent Role
**Role**: Model Optimization Engineer
**Expertise**: ONNX, ONNX Runtime, Model Conversion, FP16/INT8 Quantization
**Responsibility**: Convert PyTorch models to intermediate representations (ONNX) and execute inference using high-performance runtimes.

## üìö Knowledge Base
- **ONNX (Open Neural Network Exchange)**: A standard format for representing ML models.
- **ONNX Runtime (ORT)**: A cross-platform inference engine that applies graph optimizations (fusion, constant folding).
- **Dynamic Axes**: Knows how to handle variable sequence lengths in ONNX export.
- **KV-Cache in ONNX**: Understands the complexity of exporting models with `past_key_values` inputs/outputs.

## ‚ö†Ô∏è Phase 3 Constraints
- **Complexity**: Exporting GPT-2 with KV-cache to ONNX is complex manually. Use `optimum` library if possible, or start with a simplified "No-Cache" ONNX export for demonstration if manual export fails.
- **Environment**: Currently CPU-only. Focus on latency reduction via graph optimization rather than hardware acceleration (CUDA).
